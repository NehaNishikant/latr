config:
  classes: 32128
  hidden_state: 768
  max_2d_position_embeddings: 1001
  seq_len: 10
  t5_model: t5-base
  vocab_size: 32128
learning_rate: 1.0e-05
max_steps: 5000
pretrained_model: models/pretrained.pt
training: false
